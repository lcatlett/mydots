#!/bin/bash
# Site UUID is REQUIRED: Site UUID from Dashboard URL, e.g. 12345678-1234-1234-abcd-0123456789ab
#SITE_UUID=044a8378-d177-4357-919b-8a4906b1c53f
# Environment is REQUIRED: dev/test/live/or a Multidev
#ENV=intg


SITE=$1
ENV=$2

echo "Setting required configuration values for $SITE"

if [ "$ENV" == "all" ]; then
    ENVLIST="$(terminus env:list $SITE --format=list --fields=id)"
    IFS=$'\n' paths=($ENVLIST)

else
    ENVLIST=$ENV
    IFS=, paths=($ENVLIST)
fi

for (( i=0; i<${#paths[@]}; i++ ))
do
    ENVI=${paths[$i]}
    echo "Collecting logs for $ENVI"

    ########### Additional settings you don't have to change unless you want to ###########
    # OPTIONAL: Set AGGREGATE_NGINX to true if you want to aggregate nginx logs.
    #  WARNING: If set to true, this will potentially create a large file
    AGGREGATE_NGINX=false
    # if you just want to aggregate the files already collected, set COLLECT_LOGS to FALSE
    COLLECT_LOGS=true
    # CLEANUP_AGGREGATE_DIR removes all logs except combined.logs from aggregate-logs directory.
    CLEANUP_AGGREGATE_DIR=false

    for ENV_SITE in $ENVI; do

        ENV_DATA=$(terminus connection:info $SITE.$ENV_SITE --format=string --fields=sftp_username)

        ENV_FIELDS=($(echo $ENV_DATA))

        if [ -z "${ENV_FIELDS[0]}" ]; then
        error "Error generating configuration values $SITE. Are you authenticated to terminus?"
        exit 1
        fi

        export ENV_UUID=${ENV_FIELDS[0]}

    # DEST_DATA=$(terminus env:info $SITE --format=string --fields=id)
    # DEST_FIELDS=($(echo $DEST_DATA))
    # export DEST_DIR=${DEST_FIELDS[0]}

        if [ $COLLECT_LOGS == true ]; then
        echo 'COLLECT_LOGS set to $COLLECT_LOGS. Beginning the process...'

    # Create a directory for the logs if it doesnt exist

        export DEST="$HOME/logs/"$SITE"/"$ENV_SITE

        if [ ! -d "$DEST" ]; then
        mkdir -p "$DEST"
        fi

        echo "Collecting logs in $DEST"

        cd $DEST


        for app_server in $(dig +short -4 appserver.$ENV_UUID.drush.in);
        do
            cd $DEST
            rsync -rlvz --size-only --ipv4 --progress -e "ssh -p 2222" "$ENV_UUID@$app_server:logs" "app_server_$app_server"
        done

        # Include MySQL logs
        for db_server in $(dig +short -4 dbserver.$ENV_UUID.drush.in);
        do  
            cd $DEST
            rsync -rlvz --size-only --ipv4 --progress -e "ssh -p 2222" "$ENV_UUID@$db_server:logs" "db_server_$db_server"
        done
        else
        echo 'skipping the collection of logs..'
        fi

        if [ $AGGREGATE_NGINX == true ]; then
        echo 'AGGREGATE_NGINX set to $AGGREGATE_NGINX. Starting the process of combining nginx-access logs...'
        mkdir aggregate-logs

        for d in $(ls -d app*/logs/nginx); do
            for f in $(ls -f "$d"); do
            if [[ $f == "nginx-access.log" ]]; then
                cat "$d/$f" >> aggregate-logs/nginx-access.log
                cat "" >> aggregate-logs/nginx-access.log
            fi
            if [[ $f =~ \.gz ]]; then
                cp -v "$d/$f" aggregate-logs/
            fi
            done
        done

        echo "unzipping nginx-access logs in aggregate-logs directory..."
        for f in $(ls -f aggregate-logs); do
            if [[ $f =~ \.gz ]]; then
            gunzip aggregate-logs/"$f"
            fi
        done

        echo "combining all nginx access logs..."
        for f in $(ls -f aggregate-logs); do
            cat aggregate-logs/"$f" >> aggregate-logs/combined.logs
        done
        echo 'the combined logs file can be found in aggregate-logs/combined.logs'
        else
        echo "AGGREGATE_NGINX set to $AGGREGATE_NGINX. So we're done."
        fi

        if [ $CLEANUP_AGGREGATE_DIR == true ]; then
        echo 'CLEANUP_AGGREGATE_DIR set to $CLEANUP_AGGREGATE_DIR. Cleaning up the aggregate-logs directory'
        find ./aggregate-logs/ -name 'nginx-access*' -print -exec rm {} \;
        fi
    done

    echo "[$i] ${paths[$i]}"
done





